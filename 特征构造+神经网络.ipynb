{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"collapsed":false,"id":"75355D43280D419597BF2C866CCDA70C","jupyter":{},"notebookId":"63c954db1971ee1e8fd6cf7c","scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true},"outputs":[],"source":["# 本地\n","input_dir,project_dir = r\"G:\\\\Browser\\\\GAIDC_preliminary_A\\\\\", r\"G:\\\\Browser\\\\GAIDC_preliminary_A\\\\\"\n","# 和鲸\n","# input_dir,project_dir = r\"/home/mw/input/rcxx20231783/\", r\"/home/mw/project/\"\n","# # AIstudio\n","# input_dir,project_dir = r\"/home/aistudio/data/data187170/\", r\"/home/aistudio/work/\"\n","\n","test_dir = input_dir + 'preliminary_A.csv'\n","train_dir = input_dir + 'train.csv'\n","prediction_dir = project_dir + 'prediction.csv'\n","pickle_dir = project_dir + 'df.pickle'\n","\n","# 全局超参\n","n_jobs = 8 # 核心数\n","random_state = 123 # 随机数种子\n","n_estimators = 10000 # 迭代次数\n","early_stopping_rounds = int(n_estimators/10)\n","\n","frac = 1 # 读取数据的比例（用于debug）"]},{"cell_type":"code","execution_count":2,"metadata":{"collapsed":false,"id":"76CB2673F2784F66A012735CD7E544E8","jupyter":{},"notebookId":"63c954db1971ee1e8fd6cf7c","scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true},"outputs":[],"source":["drop_list = ['date_id']\n","y_cols = 'y'"]},{"cell_type":"code","execution_count":4,"metadata":{"collapsed":false,"id":"E42F5CAD74904C60A99F68011F61789F","jupyter":{},"notebookId":"63c954db1971ee1e8fd6cf7c","scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true},"outputs":[],"source":["import sklearn\n","from sklearn.metrics import roc_auc_score\n","from sklearn.metrics import accuracy_score\n","from sklearn.metrics import explained_variance_score\n","from sklearn.model_selection import GridSearchCV\n","\n","from sklearn.model_selection import StratifiedKFold\n","from sklearn.model_selection import KFold\n","from sklearn.model_selection import cross_val_score\n","from sklearn.preprocessing import LabelEncoder\n","import pandas as pd\n","import numpy as np\n","from sklearn. model_selection import train_test_split\n","from tqdm import tqdm\n","import datetime\n","import time\n","import re\n","import pickle\n","import math\n","\n","\n","\n","from sklearn.ensemble import RandomForestRegressor\n","from lightgbm import LGBMRegressor\n","import lightgbm as lgb\n","from lightgbm import LGBMClassifier\n","import gc\n","from sklearn.metrics import roc_auc_score\n","pd.set_option('display.max_columns', None)\n","pd.set_option('display.max_rows', 300)\n","import warnings\n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"code","execution_count":5,"metadata":{"collapsed":false,"id":"81090E1850B24EC78BAFD8B486F837C0","jupyter":{},"notebookId":"63c954db1971ee1e8fd6cf7c","scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true},"outputs":[{"data":{"text/plain":["4"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["# df = pd.read_csv(\"/home/mw/input/pre8881/train.csv\")#训练集\n","# df = pd.DataFrame(df.values[0:10000],columns=df.columns) #测试集\n","df_test = pd.read_csv(test_dir)\n","df_train = pd.read_csv(train_dir)\n","# df_train.dropna(thresh = len(df_train.columns) - df_train.isnull().sum(axis=1).max() + 1,inplace=True)#dropna空最多的TopN\n","df = df_train.append(df_test, sort=False)#.sample(frac=0.1, random_state=random_state)# 合并测试集与训练集\n","# del df_train,df_test\n","gc.collect()"]},{"cell_type":"markdown","metadata":{"collapsed":false,"id":"D7B3299960B24E559F3D98AC8443D1A4","jupyter":{},"notebookId":"63c954db1971ee1e8fd6cf7c","scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true},"source":["## 数据预处理\n"]},{"cell_type":"code","execution_count":6,"metadata":{"collapsed":false,"id":"C0456CC39D2D412BACB1C0BE88E44581","jupyter":{},"notebookId":"63c954db1971ee1e8fd6cf7c","scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 3/3 [00:00<00:00, 150.01it/s]\n"]}],"source":["le = LabelEncoder()\n","for f in tqdm(list(df.drop(columns=['id']).select_dtypes(include='object'))):\n","    '''\n","    LabelEncoding (for object)\n","    '''\n","    try:\n","        if f==\"id\": # 保留id\n","            continue\n","        df[f] = df[f].astype('float')# 将数字转成数值型数据\n","    except:\n","        df[f] = le.fit_transform(df[f].astype('str')).astype('int')# 字符串label化"]},{"cell_type":"markdown","metadata":{"collapsed":false,"id":"AA9DFC4279F34C2E9F228AFAF09858C0","jupyter":{},"notebookId":"63c954db1971ee1e8fd6cf7c","scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true},"source":["## 构造衍生业务特征"]},{"cell_type":"code","execution_count":7,"metadata":{"collapsed":false,"id":"97E34BCF840B4F578A3C8853BAA9BDC0","jupyter":{},"notebookId":"63c954db1971ee1e8fd6cf7c","scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 11/11 [00:00<00:00, 57.70it/s]\n"]}],"source":["# 数量编码\n","groupby_list = ['transformers', 'month','date_id', 'is_weekend', 'time', 'L1', 'L2', 'L3', 'L4', 'L5', 'L6']\n","for name in tqdm(groupby_list):\n","    # 加上同类数属性列\n","    df_temp = df.groupby(name).size().reset_index()#重置索引\n","    df_temp.columns = [name] + [\"num_in_\"+name]\n","    df = df.merge(df_temp, how='left')  # 左合并   "]},{"cell_type":"code","execution_count":8,"metadata":{"collapsed":false,"id":"2171D6C8ED0C4FFAB4419EEE4891CA4C","jupyter":{},"notebookId":"63c954db1971ee1e8fd6cf7c","scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true},"outputs":[],"source":["L_list = ['L1', 'L2', 'L3', 'L4', 'L5', 'L6']\n","L_norm_list = [i+\"_norm\" for i in L_list]\n","max_min_scaler = lambda x : (x-x.min())/(x.max()-x.min())\n","for i in L_list: # 将L1-6进行min-max归一化\n","    df[f'{i}_norm'] = df[[i]].apply(max_min_scaler).values\n","df[\"L_norm_sum\"] = df[L_norm_list].sum(axis=1) # 归一化总和\n","df[\"L_sum\"] = df[L_list].sum(axis=1) # 总和\n","df['L_norm_std']  = df[L_norm_list].std(axis=1) # 方差\n","df['L_std']  = df[L_list].std(axis=1) # 方差"]},{"cell_type":"code","execution_count":9,"metadata":{"collapsed":false,"id":"3AD477F391A140B88D0F907A6B15AA8E","jupyter":{},"notebookId":"63c954db1971ee1e8fd6cf7c","scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true},"outputs":[],"source":["# 猜测复杂L1-L6是否大于0可能会有影响\n","ge0 = lambda x: 1 if x>=0 else 0\n","L_ge0_list = [f\"is_{i}_ge0\" for i in L_list]\n","for i in L_list:\n","    df[f'is_{i}_ge0'] = df[[i]].applymap(ge0).values\n","df[\"num_L_ge0\"] = df[L_ge0_list].sum(axis=1)\n","df[\"is_L_all_ge0\"] = df[\"is_L1_ge0\"] * df[\"is_L2_ge0\"] * df[\"is_L3_ge0\"] * df[\"is_L4_ge0\"] * df[\"is_L5_ge0\"] * df[\"is_L6_ge0\"]"]},{"cell_type":"markdown","metadata":{"collapsed":false,"id":"D07E69661ECC4AA9945CB56ADBEE849F","jupyter":{},"notebookId":"63c954db1971ee1e8fd6cf7c","scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true},"source":["# 特征构建"]},{"cell_type":"code","execution_count":10,"metadata":{"collapsed":false,"id":"D053FC43D8FF4A688B79E26C88BD32D0","jupyter":{},"notebookId":"63c954db1971ee1e8fd6cf7c","scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true},"outputs":[],"source":["# 统计特征用到的函数\n","def stat(df, df_merge, cols, agg): # 每次只计算一列cols\n","    # 测试集df_merge关于训练集df的cols列agg统计特征\n","    group = df.groupby(cols).agg(agg) #算出cols属性在df中的agg属性\n","    columns = []\n","    for on, methods in agg.items(): \n","        #items为y_cols、mean;此处为字典变量————'y_cols':['mean','std']\n","        for method in methods: # methods也可能有多个\n","            if str(type(method)) == '<class \\'function\\'>': # 匿名函数会以地址命名，造成列名不同，所以应该更名\n","                method = 'mode'\n","            columns.append('{}_{}_{}'.format('_'.join(cols), on, method)) # 用_连接，规定分组结果group的属性名\n","    group.columns = columns\n","    group.reset_index(inplace=True)\n","    df_merge = df_merge.merge(group, on=cols, how='left') #以cols左连接，仅与测试集拼接\n","    del (group)\n","    gc.collect()\n","    return df_merge\n","\n","\n","def statis_feat(df_know, df_unknow,A_list,target_B, methods_dict):\n","    # 计算A关于B的统计特征：\n","    # df_know训练集,df_unknow验证集,A_list需计算的特征集合,target_B目标标签,methods_dict编码方式\n","    for f in tqdm(A_list,desc='%-30s'%target_B,leave=False):\n","        df_unknow = stat(df_know, df_unknow, [f], {target_B: methods_dict}) # \n","    return df_unknow\n","\n","\n","def multi_groupby(df_fold_train,df_fold_val,multi_groupby_cols,target_B, methods_dict):\n","    ''' \n","    计算测试集df_fold_val关于训练集df_fold_train的multi_groupby_cols组合列methods_dict统计特征。\n","    注意！如果df_fold_val在df_fold_train中找不到相应的值，则会置为nan\n","    '''\n","    multi_groupby_df1 = df_fold_train.groupby(multi_groupby_cols).agg({target_B: methods_dict})\n","    multi_groupby_df1.columns=[\"_\".join(multi_groupby_cols+[target_B,\"_\".join(methods_dict)])]\n","    df_fold_val = df_fold_val.merge(multi_groupby_df1,how='left',left_on=multi_groupby_cols,right_index=True)\n","    return df_fold_val\n"]},{"cell_type":"code","execution_count":11,"metadata":{"collapsed":false,"id":"0EBD788D423148579FA423B88119386A","jupyter":{},"notebookId":"63c954db1971ee1e8fd6cf7c","scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true},"outputs":[],"source":["# 组合特征目标编码\n","# multi_groupby_cols = [\n","# \t   ['month','is_weekend'],['transformers','month']]\n","def generate_multi_groupby_cols(target:str,rank:int)->list:\n","    multi_groupby_cols =  []\n","    feature_list = ['transformers', 'month', 'is_weekend', 'time', 'L1', 'L2', 'L3', 'L4', 'L5', 'L6']\n","    if target!=\"y\":\n","        feature_list.remove(target)\n","\n","    if rank>=1:\n","        # 一阶\n","        for i in range(len(feature_list)):\n","            multi_groupby_cols.append([feature_list[i]])\n","    if rank>=2:  \n","        # 二阶\n","        for i in range(len(feature_list)):\n","            for j in range(i+1,len(feature_list)):\n","                multi_groupby_cols.append([feature_list[i],feature_list[j]])\n","    if rank>=3:\n","        # 三阶\n","        for i in range(len(feature_list)-2):\n","            for j in range(i+1,len(feature_list)-1):\n","                for h in range(j+1,len(feature_list)):\n","                    multi_groupby_cols.append([feature_list[i],feature_list[j],feature_list[h]])\n","    if rank>=4:\n","        # 四阶\n","        for x in range(len(feature_list)-3):\n","            for i in range(x+1,len(feature_list)-2):\n","                for j in range(i+1,len(feature_list)-1):\n","                    for h in range(j+1,len(feature_list)):\n","                        multi_groupby_cols.append([feature_list[x],feature_list[i],feature_list[j],feature_list[h]]) \n","    if rank>=5:\n","        # 五阶\n","        for x in range(len(feature_list)-4):\n","            for y in range(x+1,len(feature_list)-3):\n","                for i in range(y+1,len(feature_list)-2):\n","                    for j in range(i+1,len(feature_list)-1):\n","                        for h in range(j+1,len(feature_list)):\n","                            multi_groupby_cols.append([feature_list[x],feature_list[y],feature_list[i],feature_list[j],feature_list[h]])              \n","    return multi_groupby_cols\n","y_multi_groupby_cols = generate_multi_groupby_cols('y',4)\n","L1_multi_groupby_cols = generate_multi_groupby_cols('L1',2)\n","L2_multi_groupby_cols = generate_multi_groupby_cols('L2',2)\n","L3_multi_groupby_cols = generate_multi_groupby_cols('L3',2)\n","L4_multi_groupby_cols = generate_multi_groupby_cols('L4',2)\n","L5_multi_groupby_cols = generate_multi_groupby_cols('L5',2)\n","L6_multi_groupby_cols = generate_multi_groupby_cols('L6',2)\n","y_multi_groupby_cols = [['transformers'], ['month'], ['is_weekend'], ['time']]"]},{"cell_type":"code","execution_count":12,"metadata":{"collapsed":false,"id":"9D561A443186484C9FAFF3227E8F344E","jupyter":{},"notebookId":"63c954db1971ee1e8fd6cf7c","scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Fold_1 Featuring ===========Sun Mar  5 19:10:47 2023\n","\n"]},{"name":"stderr","output_type":"stream","text":["                                                                     \r"]},{"name":"stdout","output_type":"stream","text":["\n","Fold_2 Featuring ===========Sun Mar  5 19:10:47 2023\n","\n"]},{"name":"stderr","output_type":"stream","text":["                                                                     \r"]},{"name":"stdout","output_type":"stream","text":["\n","Fold_3 Featuring ===========Sun Mar  5 19:10:47 2023\n","\n"]},{"name":"stderr","output_type":"stream","text":["                                                                     "]},{"name":"stdout","output_type":"stream","text":["\n","Fold_4 Featuring ===========Sun Mar  5 19:10:47 2023\n","\n"]},{"name":"stderr","output_type":"stream","text":["                                                                     \r"]},{"name":"stdout","output_type":"stream","text":["\n","Fold_5 Featuring ===========Sun Mar  5 19:10:47 2023\n","\n"]},{"name":"stderr","output_type":"stream","text":["                                                                     "]},{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","Int64Index: 48000 entries, 1 to 47999\n","Data columns (total 46 columns):\n"," #   Column               Non-Null Count  Dtype  \n","---  ------               --------------  -----  \n"," 0   id                   48000 non-null  object \n"," 1   transformers         48000 non-null  int32  \n"," 2   date_id              48000 non-null  int32  \n"," 3   month                48000 non-null  int64  \n"," 4   is_weekend           48000 non-null  int64  \n"," 5   time                 48000 non-null  int32  \n"," 6   L1                   48000 non-null  float64\n"," 7   L2                   48000 non-null  float64\n"," 8   L3                   48000 non-null  float64\n"," 9   L4                   48000 non-null  float64\n"," 10  L5                   48000 non-null  float64\n"," 11  L6                   48000 non-null  float64\n"," 12  y                    38400 non-null  float64\n"," 13  num_in_transformers  48000 non-null  int64  \n"," 14  num_in_month         48000 non-null  int64  \n"," 15  num_in_date_id       48000 non-null  int64  \n"," 16  num_in_is_weekend    48000 non-null  int64  \n"," 17  num_in_time          48000 non-null  int64  \n"," 18  num_in_L1            48000 non-null  int64  \n"," 19  num_in_L2            48000 non-null  int64  \n"," 20  num_in_L3            48000 non-null  int64  \n"," 21  num_in_L4            48000 non-null  int64  \n"," 22  num_in_L5            48000 non-null  int64  \n"," 23  num_in_L6            48000 non-null  int64  \n"," 24  L1_norm              48000 non-null  float64\n"," 25  L2_norm              48000 non-null  float64\n"," 26  L3_norm              48000 non-null  float64\n"," 27  L4_norm              48000 non-null  float64\n"," 28  L5_norm              48000 non-null  float64\n"," 29  L6_norm              48000 non-null  float64\n"," 30  L_norm_sum           48000 non-null  float64\n"," 31  L_sum                48000 non-null  float64\n"," 32  L_norm_std           48000 non-null  float64\n"," 33  L_std                48000 non-null  float64\n"," 34  is_L1_ge0            48000 non-null  int64  \n"," 35  is_L2_ge0            48000 non-null  int64  \n"," 36  is_L3_ge0            48000 non-null  int64  \n"," 37  is_L4_ge0            48000 non-null  int64  \n"," 38  is_L5_ge0            48000 non-null  int64  \n"," 39  is_L6_ge0            48000 non-null  int64  \n"," 40  num_L_ge0            48000 non-null  int64  \n"," 41  is_L_all_ge0         48000 non-null  int64  \n"," 42  transformers_y_mean  48000 non-null  float64\n"," 43  month_y_mean         48000 non-null  float64\n"," 44  is_weekend_y_mean    48000 non-null  float64\n"," 45  time_y_mean          48000 non-null  float64\n","dtypes: float64(21), int32(3), int64(21), object(1)\n","memory usage: 16.7+ MB\n"]},{"name":"stderr","output_type":"stream","text":["\r"]}],"source":["df_train = df[~df[y_cols].isnull()] # 重新分离出训练集和测试集\n","df_train = df_train.reset_index(drop=True)\n","df_test = df[df[y_cols].isnull()]\n","\n","df_train_stas_feat = None\n","# 为了防止过拟合，采取KFold法统计train训练集中的特征\n","kfold = KFold(n_splits=5, random_state=random_state, shuffle=True)\n","for fold_id, (trn_idx, val_idx) in enumerate(kfold.split(df_train, df_train[y_cols])):\n","    print(f'\\nFold_{fold_id+1} Featuring ==========={time.asctime(time.localtime(time.time()))}\\n')\n","    df_fold_train,df_fold_val = df_train.iloc[trn_idx],df_train.iloc[val_idx] # 划分训练集与验证集\n","    \n","    # 计算验证集关于训练集的单/多列组合统计特征\n","    for cols in tqdm(y_multi_groupby_cols,desc='%-30s'%'y_multi_groupby_cols',leave=False): \n","        df_fold_val = multi_groupby(df_fold_train, df_fold_val, cols,y_cols, ['mean'])\n","\n","    # for cols in tqdm(L1_multi_groupby_cols,desc='%-30s'%'L1_multi_groupby_cols',leave=False): \n","    #     df_fold_val = multi_groupby(df_fold_train, df_fold_val, cols,'L1', ['mean'])\n","    # for cols in tqdm(L2_multi_groupby_cols,desc='%-30s'%'L2_multi_groupby_cols',leave=False): \n","    #     df_fold_val = multi_groupby(df_fold_train, df_fold_val, cols,'L2', ['mean'])\n","    # for cols in tqdm(L3_multi_groupby_cols,desc='%-30s'%'L3_multi_groupby_cols',leave=False): \n","    #     df_fold_val = multi_groupby(df_fold_train, df_fold_val, cols,'L3', ['mean'])\n","    # for cols in tqdm(L4_multi_groupby_cols,desc='%-30s'%'L4_multi_groupby_cols',leave=False): \n","    #     df_fold_val = multi_groupby(df_fold_train, df_fold_val, cols,'L4', ['mean'])\n","    # for cols in tqdm(L5_multi_groupby_cols,desc='%-30s'%'L5_multi_groupby_cols',leave=False): \n","    #     df_fold_val = multi_groupby(df_fold_train, df_fold_val, cols,'L5', ['mean'])\n","    # for cols in tqdm(L6_multi_groupby_cols,desc='%-30s'%'L6_multi_groupby_cols',leave=False): \n","    #     df_fold_val = multi_groupby(df_fold_train, df_fold_val, cols,'L6', ['mean'])\n","\n","    df_train_stas_feat = pd.concat([df_train_stas_feat, df_fold_val], axis=0)# 五折之后拼成一个完整的stas_feat训练集\n","    # del df_fold_train,df_fold_val\n","    gc.collect()\n","\n","# 计算测试集关于训练集的统计特征\n","for cols in tqdm(y_multi_groupby_cols,desc='%-30s'%'y_multi_groupby_cols',leave=False):\n","    df_test = multi_groupby(df_train, df_test, cols,y_cols, ['mean'])\n","\n","# for cols in tqdm(L1_multi_groupby_cols,desc='%-30s'%'L1_multi_groupby_cols',leave=False):\n","#     df_test = multi_groupby(df_train, df_test, cols,'L1', ['mean'])\n","# for cols in tqdm(L2_multi_groupby_cols,desc='%-30s'%'L2_multi_groupby_cols',leave=False):\n","#     df_test = multi_groupby(df_train, df_test, cols,'L2', ['mean'])\n","# for cols in tqdm(L3_multi_groupby_cols,desc='%-30s'%'L3_multi_groupby_cols',leave=False):\n","#     df_test = multi_groupby(df_train, df_test, cols,'L3', ['mean'])\n","# for cols in tqdm(L4_multi_groupby_cols,desc='%-30s'%'L4_multi_groupby_cols',leave=False):\n","#     df_test = multi_groupby(df_train, df_test, cols,'L4', ['mean'])\n","# for cols in tqdm(L5_multi_groupby_cols,desc='%-30s'%'L5_multi_groupby_cols',leave=False):\n","#     df_test = multi_groupby(df_train, df_test, cols,'L5', ['mean'])\n","# for cols in tqdm(L6_multi_groupby_cols,desc='%-30s'%'L6_multi_groupby_cols',leave=False):\n","#     df_test = multi_groupby(df_train, df_test, cols,'L6', ['mean'])\n","\n","df = pd.concat([df_train_stas_feat, df_test], axis=0) # 将分别完成的训练集和测试集的stas_feat合并成最终的df\n","df.info()"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["y 9600\n"]}],"source":["for i in df.columns.values:\n","    # 填充空值，y除外\n","    if i != \"y\":\n","        df[i].fillna(-100,inplace=True)\n","\n","for i,j in zip(df.isna().sum().index, df.isna().sum()):\n","    # 无输出则无空值\n","    if(j!=0):\n","        print(i,j)\n","\n","# 分割train和test\n","df_test = df[df[y_cols].isnull()].drop(columns=drop_list)\n","df_train = df[df[y_cols].notnull()].drop(columns=drop_list)"]},{"cell_type":"code","execution_count":14,"metadata":{"collapsed":false,"id":"682DD86EA4A743B193FCAF2EF628AC56","jupyter":{},"notebookId":"63c954db1971ee1e8fd6cf7c","scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true},"outputs":[],"source":["# 使用 `pickle.dump()` 函数将变量保存到文件中\n","# with open(pickle_dir, 'wb') as f:\n","#     pickle.dump(df, f)\n","\n","# with open(pickle_dir, 'rb') as f:\n","#     df = pickle.load(f)"]},{"cell_type":"markdown","metadata":{"collapsed":false,"id":"A69272FD41B940B097E8E4CA6289888F","jupyter":{},"notebookId":"63c954db1971ee1e8fd6cf7c","scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true},"source":["# 数据训练"]},{"cell_type":"code","execution_count":15,"metadata":{"collapsed":false,"id":"44752A9CCC874D68B242DC15F23C0F6C","jupyter":{},"notebookId":"63c954db1971ee1e8fd6cf7c","scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","Index: 0 entries\n","Data columns (total 46 columns):\n"," #   Column               Non-Null Count  Dtype \n","---  ------               --------------  ----- \n"," 0   id                   0 non-null      object\n"," 1   transformers         0 non-null      object\n"," 2   date_id              0 non-null      object\n"," 3   month                0 non-null      object\n"," 4   is_weekend           0 non-null      object\n"," 5   time                 0 non-null      object\n"," 6   L1                   0 non-null      object\n"," 7   L2                   0 non-null      object\n"," 8   L3                   0 non-null      object\n"," 9   L4                   0 non-null      object\n"," 10  L5                   0 non-null      object\n"," 11  L6                   0 non-null      object\n"," 12  y                    0 non-null      object\n"," 13  num_in_transformers  0 non-null      object\n"," 14  num_in_month         0 non-null      object\n"," 15  num_in_date_id       0 non-null      object\n"," 16  num_in_is_weekend    0 non-null      object\n"," 17  num_in_time          0 non-null      object\n"," 18  num_in_L1            0 non-null      object\n"," 19  num_in_L2            0 non-null      object\n"," 20  num_in_L3            0 non-null      object\n"," 21  num_in_L4            0 non-null      object\n"," 22  num_in_L5            0 non-null      object\n"," 23  num_in_L6            0 non-null      object\n"," 24  L1_norm              0 non-null      object\n"," 25  L2_norm              0 non-null      object\n"," 26  L3_norm              0 non-null      object\n"," 27  L4_norm              0 non-null      object\n"," 28  L5_norm              0 non-null      object\n"," 29  L6_norm              0 non-null      object\n"," 30  L_norm_sum           0 non-null      object\n"," 31  L_sum                0 non-null      object\n"," 32  L_norm_std           0 non-null      object\n"," 33  L_std                0 non-null      object\n"," 34  is_L1_ge0            0 non-null      object\n"," 35  is_L2_ge0            0 non-null      object\n"," 36  is_L3_ge0            0 non-null      object\n"," 37  is_L4_ge0            0 non-null      object\n"," 38  is_L5_ge0            0 non-null      object\n"," 39  is_L6_ge0            0 non-null      object\n"," 40  num_L_ge0            0 non-null      object\n"," 41  is_L_all_ge0         0 non-null      object\n"," 42  transformers_y_mean  0 non-null      object\n"," 43  month_y_mean         0 non-null      object\n"," 44  is_weekend_y_mean    0 non-null      object\n"," 45  time_y_mean          0 non-null      object\n","dtypes: object(46)\n","memory usage: 0.0+ bytes\n"]}],"source":["# 新建一个dataframe，总行数为原df的1/48，将原df的所有feat都整合成长48的list\n","column_names = list(df.columns.values) #.remove(\"id\")\n","# column_names.remove(\"id\")\n","df_48 = pd.DataFrame(columns=column_names)\n","# test_id_list = df_test[\"id\"].values.tolist() # 存储测试集id，便于分隔\n","df_48.info()"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 517/517 [00:07<00:00, 66.10it/s]\n","100%|██████████| 483/483 [00:07<00:00, 62.53it/s]"]},{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 1000 entries, 0 to 999\n","Data columns (total 46 columns):\n"," #   Column               Non-Null Count  Dtype \n","---  ------               --------------  ----- \n"," 0   id                   1000 non-null   object\n"," 1   transformers         1000 non-null   object\n"," 2   date_id              1000 non-null   object\n"," 3   month                1000 non-null   object\n"," 4   is_weekend           1000 non-null   object\n"," 5   time                 1000 non-null   object\n"," 6   L1                   1000 non-null   object\n"," 7   L2                   1000 non-null   object\n"," 8   L3                   1000 non-null   object\n"," 9   L4                   1000 non-null   object\n"," 10  L5                   1000 non-null   object\n"," 11  L6                   1000 non-null   object\n"," 12  y                    1000 non-null   object\n"," 13  num_in_transformers  1000 non-null   object\n"," 14  num_in_month         1000 non-null   object\n"," 15  num_in_date_id       1000 non-null   object\n"," 16  num_in_is_weekend    1000 non-null   object\n"," 17  num_in_time          1000 non-null   object\n"," 18  num_in_L1            1000 non-null   object\n"," 19  num_in_L2            1000 non-null   object\n"," 20  num_in_L3            1000 non-null   object\n"," 21  num_in_L4            1000 non-null   object\n"," 22  num_in_L5            1000 non-null   object\n"," 23  num_in_L6            1000 non-null   object\n"," 24  L1_norm              1000 non-null   object\n"," 25  L2_norm              1000 non-null   object\n"," 26  L3_norm              1000 non-null   object\n"," 27  L4_norm              1000 non-null   object\n"," 28  L5_norm              1000 non-null   object\n"," 29  L6_norm              1000 non-null   object\n"," 30  L_norm_sum           1000 non-null   object\n"," 31  L_sum                1000 non-null   object\n"," 32  L_norm_std           1000 non-null   object\n"," 33  L_std                1000 non-null   object\n"," 34  is_L1_ge0            1000 non-null   object\n"," 35  is_L2_ge0            1000 non-null   object\n"," 36  is_L3_ge0            1000 non-null   object\n"," 37  is_L4_ge0            1000 non-null   object\n"," 38  is_L5_ge0            1000 non-null   object\n"," 39  is_L6_ge0            1000 non-null   object\n"," 40  num_L_ge0            1000 non-null   object\n"," 41  is_L_all_ge0         1000 non-null   object\n"," 42  transformers_y_mean  1000 non-null   object\n"," 43  month_y_mean         1000 non-null   object\n"," 44  is_weekend_y_mean    1000 non-null   object\n"," 45  time_y_mean          1000 non-null   object\n","dtypes: object(46)\n","memory usage: 359.5+ KB\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["feat_name = df_48.columns.values\n","# feat_name = column_names\n","# 把M1和M2分开\n","for transformers in df[\"transformers\"].value_counts().index.values:\n","    date_id_list = df[df[\"transformers\"] == transformers][\"date_id\"].value_counts().index.values\n","    for date_id in tqdm(date_id_list):\n","        tmp = df.query(f' transformers=={transformers} and date_id=={date_id} ')\n","        data = {i: tmp[i].values for i in feat_name}\n","        # data = {\n","        #     \"y\": df_list[\"y\"].values,\n","        #     \"L1\": df_list[\"L1\"].values,\n","        #     \"L2\": df_list[\"L2\"].values,\n","        #     \"L3\": df_list[\"L3\"].values,\n","        #     }\n","        df_48 = df_48.append(data, ignore_index=True)\n","# df_48[[\"id\",\"y\"]]\n","df_48.info()"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"data":{"text/plain":["(200, 800)"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["# 区分train和test\n","test_no_list = []\n","train_no_list = [i for i in range(1000)]\n","for i,j in enumerate(df_48[\"y\"]):\n","    if j.tolist() != j.tolist(): # 即为nan\n","        # print(j)\n","        test_no_list.append(i)\n","        train_no_list.remove(i)\n","\n","len(test_no_list), len(train_no_list)"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 1000 entries, 0 to 999\n","Data columns (total 46 columns):\n"," #   Column               Non-Null Count  Dtype \n","---  ------               --------------  ----- \n"," 0   id                   1000 non-null   object\n"," 1   transformers         1000 non-null   object\n"," 2   date_id              1000 non-null   object\n"," 3   month                1000 non-null   object\n"," 4   is_weekend           1000 non-null   object\n"," 5   time                 1000 non-null   object\n"," 6   L1                   1000 non-null   object\n"," 7   L2                   1000 non-null   object\n"," 8   L3                   1000 non-null   object\n"," 9   L4                   1000 non-null   object\n"," 10  L5                   1000 non-null   object\n"," 11  L6                   1000 non-null   object\n"," 12  num_in_transformers  1000 non-null   object\n"," 13  num_in_month         1000 non-null   object\n"," 14  num_in_date_id       1000 non-null   object\n"," 15  num_in_is_weekend    1000 non-null   object\n"," 16  num_in_time          1000 non-null   object\n"," 17  num_in_L1            1000 non-null   object\n"," 18  num_in_L2            1000 non-null   object\n"," 19  num_in_L3            1000 non-null   object\n"," 20  num_in_L4            1000 non-null   object\n"," 21  num_in_L5            1000 non-null   object\n"," 22  num_in_L6            1000 non-null   object\n"," 23  L1_norm              1000 non-null   object\n"," 24  L2_norm              1000 non-null   object\n"," 25  L3_norm              1000 non-null   object\n"," 26  L4_norm              1000 non-null   object\n"," 27  L5_norm              1000 non-null   object\n"," 28  L6_norm              1000 non-null   object\n"," 29  L_norm_sum           1000 non-null   object\n"," 30  L_sum                1000 non-null   object\n"," 31  L_norm_std           1000 non-null   object\n"," 32  L_std                1000 non-null   object\n"," 33  is_L1_ge0            1000 non-null   object\n"," 34  is_L2_ge0            1000 non-null   object\n"," 35  is_L3_ge0            1000 non-null   object\n"," 36  is_L4_ge0            1000 non-null   object\n"," 37  is_L5_ge0            1000 non-null   object\n"," 38  is_L6_ge0            1000 non-null   object\n"," 39  num_L_ge0            1000 non-null   object\n"," 40  is_L_all_ge0         1000 non-null   object\n"," 41  transformers_y_mean  1000 non-null   object\n"," 42  month_y_mean         1000 non-null   object\n"," 43  is_weekend_y_mean    1000 non-null   object\n"," 44  time_y_mean          1000 non-null   object\n"," 45  y                    1000 non-null   object\n","dtypes: object(46)\n","memory usage: 359.5+ KB\n"]}],"source":["# 把y换到最后一列\n","exc_y_list = df_48.columns.values.tolist()\n","exc_y_list.remove('y')\n","exc_y_list\n","y_value = df_48[\"y\"].values\n","# df_48 = df_48[exc_y_list].copy()\n","df_48 = df_48.drop(columns=[\"y\"])\n","df_48[\"y\"] = y_value\n","df_48.info()\n","# test_no_list"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"data":{"text/plain":["((800, 44, 48), (800, 1, 48))"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["# 数据框转换为numpy数组\n","df_train_np = df_48.iloc[train_no_list].drop(columns=\"id\").to_numpy() # 抽取出train\n","\n","diff = len([\"id\",\"y\"])\n","# 提取出list\n","df_train_list = []\n","for i in range(len(df_48.columns.values) - diff): # 去除y和id所以减2\n","    df_train_list.append(df_train_np[:, i])\n","label = df_train_np[:, -1] # 取y\n","\n","# 将特征A，特征B和标签转换为三维张量。将数值类型从list转换为array\n","x_train = np.array(\n","    [\n","        [df_train_list[i][j] for i in range(len(df_48.columns.values) - diff)] \n","        for j in range(len(df_train_list[0]))\n","    ]\n","    )\n","# 优先外层的for\n","# Dense需要T转置,可能需要在label[i]外再加一层[]\n","y_train = np.array([[label[i]] for i in range(len(label))]) #.T \n","\n","# ================测试集================\n","\n","df_test_np = df_48.iloc[test_no_list].drop(columns=\"id\").to_numpy() # 抽取出test\n","# 提取出list\n","df_test_list = []\n","for i in range(len(df_48.columns.values) - diff):\n","    df_test_list.append(df_test_np[:, i])\n","\n","x_test = np.array(\n","    [\n","        [df_test_list[i][j] for i in range(len(df_48.columns.values) - diff)] \n","        for j in range(len(df_test_list[0]))\n","    ]\n","    )\n","x_train.shape, y_train.shape"]},{"cell_type":"code","execution_count":20,"metadata":{"collapsed":false,"id":"B3F380EE53B94EE18AB973806D9EF3E1","jupyter":{},"notebookId":"63cac24d30f8a115ae76faa0","scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Fold_1 Featuring ===========Sun Mar  5 19:11:08 2023\n","\n","Epoch 1/2000\n","80/80 [==============================] - 5s 12ms/step - loss: 306.8897 - mae: 13.4202 - val_loss: 152.8471 - val_mae: 9.5010\n","Epoch 2/2000\n","80/80 [==============================] - 1s 8ms/step - loss: 154.8224 - mae: 10.0285 - val_loss: 137.5700 - val_mae: 9.6111\n","Epoch 3/2000\n","80/80 [==============================] - 1s 8ms/step - loss: 150.9140 - mae: 10.2858 - val_loss: 136.8925 - val_mae: 9.5072\n","Epoch 4/2000\n","80/80 [==============================] - 1s 8ms/step - loss: 150.3680 - mae: 10.2241 - val_loss: 137.0502 - val_mae: 9.5452\n","Epoch 5/2000\n","80/80 [==============================] - 1s 9ms/step - loss: 150.2576 - mae: 10.2336 - val_loss: 137.8802 - val_mae: 9.6480\n","Epoch 6/2000\n","80/80 [==============================] - 1s 8ms/step - loss: 150.4595 - mae: 10.2189 - val_loss: 137.6074 - val_mae: 9.6188\n","Epoch 7/2000\n","80/80 [==============================] - 1s 8ms/step - loss: 150.5839 - mae: 10.3031 - val_loss: 137.0701 - val_mae: 9.5403\n","Epoch 8/2000\n","80/80 [==============================] - 1s 8ms/step - loss: 150.4539 - mae: 10.1863 - val_loss: 138.9159 - val_mae: 9.7429\n","Epoch 9/2000\n","80/80 [==============================] - 1s 8ms/step - loss: 150.4756 - mae: 10.2740 - val_loss: 137.5173 - val_mae: 9.6069\n","Epoch 10/2000\n","80/80 [==============================] - 1s 8ms/step - loss: 150.7752 - mae: 10.2577 - val_loss: 138.0607 - val_mae: 9.6661\n","Epoch 11/2000\n","80/80 [==============================] - 1s 8ms/step - loss: 150.3730 - mae: 10.2419 - val_loss: 136.9181 - val_mae: 9.5149\n","Epoch 12/2000\n","80/80 [==============================] - 1s 8ms/step - loss: 150.5853 - mae: 10.2405 - val_loss: 137.7441 - val_mae: 9.6336\n","Epoch 13/2000\n","80/80 [==============================] - 1s 8ms/step - loss: 150.3153 - mae: 10.2319 - val_loss: 137.6213 - val_mae: 9.6163\n","Epoch 14/2000\n","80/80 [==============================] - 1s 8ms/step - loss: 150.4523 - mae: 10.1771 - val_loss: 140.9900 - val_mae: 9.8957\n","Epoch 15/2000\n","80/80 [==============================] - 1s 8ms/step - loss: 150.7729 - mae: 10.2938 - val_loss: 136.9855 - val_mae: 9.5271\n","(160, 48)\n","[[17.831835 17.635532 17.993088 ... 20.908085 20.253525 19.279713]\n"," [17.831814 17.635584 17.99307  ... 20.908146 20.253561 19.279682]\n"," [17.831781 17.63555  17.993055 ... 20.908121 20.253607 19.27973 ]\n"," ...\n"," [17.831821 17.635561 17.993088 ... 20.908104 20.253534 19.279697]\n"," [17.83182  17.635569 17.993101 ... 20.908134 20.253563 19.279716]\n"," [17.831776 17.635548 17.993078 ... 20.908092 20.253572 19.279705]]\n","[[17.831808 17.635553 17.993053 ... 20.908104 20.253525 19.279667]\n"," [17.831816 17.635561 17.993063 ... 20.908113 20.25353  19.279682]\n"," [17.831818 17.635565 17.993065 ... 20.908115 20.253534 19.279686]\n"," ...\n"," [17.83182  17.635565 17.993063 ... 20.908113 20.253534 19.279686]\n"," [17.831806 17.63555  17.993052 ... 20.908104 20.253523 19.279665]\n"," [17.831806 17.635553 17.993053 ... 20.9081   20.253527 19.279665]]\n","\n","Fold_2 Featuring ===========Sun Mar  5 19:11:25 2023\n","\n","Epoch 1/2000\n","80/80 [==============================] - 2s 11ms/step - loss: 285.9762 - mae: 12.9239 - val_loss: 154.6147 - val_mae: 9.6171\n","Epoch 2/2000\n","80/80 [==============================] - 1s 8ms/step - loss: 154.5927 - mae: 10.1662 - val_loss: 136.5687 - val_mae: 9.5626\n","Epoch 3/2000\n","80/80 [==============================] - 1s 8ms/step - loss: 150.4950 - mae: 10.1680 - val_loss: 136.2945 - val_mae: 9.5978\n","Epoch 4/2000\n","80/80 [==============================] - 1s 8ms/step - loss: 150.2271 - mae: 10.2144 - val_loss: 136.8362 - val_mae: 9.5396\n","Epoch 5/2000\n","80/80 [==============================] - 1s 8ms/step - loss: 150.9310 - mae: 10.1795 - val_loss: 136.7995 - val_mae: 9.5412\n","Epoch 6/2000\n","80/80 [==============================] - 1s 8ms/step - loss: 151.1237 - mae: 10.2370 - val_loss: 136.8030 - val_mae: 9.5422\n","Epoch 7/2000\n","80/80 [==============================] - 1s 8ms/step - loss: 150.9670 - mae: 10.2079 - val_loss: 136.6237 - val_mae: 9.5581\n","Epoch 8/2000\n","80/80 [==============================] - 1s 8ms/step - loss: 150.8887 - mae: 10.2042 - val_loss: 136.3313 - val_mae: 9.5923\n","Epoch 9/2000\n","80/80 [==============================] - 1s 8ms/step - loss: 150.9998 - mae: 10.2061 - val_loss: 136.9575 - val_mae: 9.5340\n","Epoch 10/2000\n","80/80 [==============================] - 1s 8ms/step - loss: 150.5349 - mae: 10.2292 - val_loss: 136.3174 - val_mae: 9.5980\n","Epoch 11/2000\n","80/80 [==============================] - 1s 8ms/step - loss: 150.9493 - mae: 10.1635 - val_loss: 136.3050 - val_mae: 9.6058\n","Epoch 12/2000\n","80/80 [==============================] - 1s 8ms/step - loss: 150.9935 - mae: 10.2103 - val_loss: 136.4209 - val_mae: 9.5811\n","Epoch 13/2000\n","80/80 [==============================] - 1s 8ms/step - loss: 150.6411 - mae: 10.2124 - val_loss: 136.2484 - val_mae: 9.6339\n","Epoch 14/2000\n","80/80 [==============================] - 1s 8ms/step - loss: 150.8893 - mae: 10.1892 - val_loss: 136.3796 - val_mae: 9.5833\n","(160, 48)\n","[[18.23787  17.997393 18.449598 ... 21.072554 20.462358 19.553564]\n"," [18.237865 17.997416 18.449608 ... 21.072577 20.46237  19.553564]\n"," [18.23787  17.997366 18.449574 ... 21.072535 20.46233  19.553562]\n"," ...\n"," [18.237886 17.997372 18.449598 ... 21.072542 20.462364 19.553572]\n"," [18.237913 17.997366 18.449617 ... 21.072557 20.462332 19.553562]\n"," [18.237907 17.997524 18.449673 ... 21.072659 20.462473 19.55362 ]]\n","[[18.237865 17.99729  18.449535 ... 21.072489 20.462248 19.553514]\n"," [18.237871 17.997292 18.449541 ... 21.072493 20.462254 19.553518]\n"," [18.23788  17.997295 18.449547 ... 21.0725   20.462261 19.553528]\n"," ...\n"," [18.237875 17.997293 18.449547 ... 21.072495 20.462257 19.553524]\n"," [18.237864 17.997286 18.449535 ... 21.072485 20.462246 19.55351 ]\n"," [18.237852 17.997284 18.449528 ... 21.072477 20.462236 19.553501]]\n","\n","Fold_3 Featuring ===========Sun Mar  5 19:11:36 2023\n","\n","Epoch 1/2000\n","80/80 [==============================] - 2s 11ms/step - loss: 285.1834 - mae: 12.9974 - val_loss: 158.1632 - val_mae: 9.8431\n","Epoch 2/2000\n","80/80 [==============================] - 1s 8ms/step - loss: 150.4286 - mae: 9.9879 - val_loss: 144.3668 - val_mae: 9.9192\n","Epoch 3/2000\n","80/80 [==============================] - 1s 8ms/step - loss: 148.8118 - mae: 10.1378 - val_loss: 144.3568 - val_mae: 9.9096\n","Epoch 4/2000\n","80/80 [==============================] - 1s 8ms/step - loss: 148.9388 - mae: 10.1525 - val_loss: 144.4779 - val_mae: 9.8824\n","Epoch 5/2000\n","80/80 [==============================] - 1s 8ms/step - loss: 148.8767 - mae: 10.1349 - val_loss: 144.4925 - val_mae: 9.8795\n","Epoch 6/2000\n","80/80 [==============================] - 1s 8ms/step - loss: 150.0345 - mae: 10.1739 - val_loss: 144.4270 - val_mae: 9.8953\n","Epoch 7/2000\n","80/80 [==============================] - 1s 8ms/step - loss: 149.3865 - mae: 10.1226 - val_loss: 144.6194 - val_mae: 9.8642\n","Epoch 8/2000\n","80/80 [==============================] - 1s 8ms/step - loss: 148.9375 - mae: 10.1649 - val_loss: 144.3277 - val_mae: 9.9184\n","Epoch 9/2000\n","80/80 [==============================] - 1s 8ms/step - loss: 148.9638 - mae: 10.1122 - val_loss: 144.4240 - val_mae: 9.9689\n","Epoch 10/2000\n","80/80 [==============================] - 1s 8ms/step - loss: 148.8973 - mae: 10.1341 - val_loss: 144.3747 - val_mae: 9.9226\n","Epoch 11/2000\n","80/80 [==============================] - 1s 8ms/step - loss: 149.4477 - mae: 10.2117 - val_loss: 144.6967 - val_mae: 9.8579\n","Epoch 12/2000\n","80/80 [==============================] - 1s 10ms/step - loss: 148.8058 - mae: 10.0617 - val_loss: 144.3512 - val_mae: 9.9365\n","Epoch 13/2000\n","80/80 [==============================] - 1s 9ms/step - loss: 148.8480 - mae: 10.2028 - val_loss: 145.2018 - val_mae: 9.8307\n","Epoch 14/2000\n","80/80 [==============================] - 1s 9ms/step - loss: 149.7361 - mae: 10.1055 - val_loss: 144.3331 - val_mae: 9.9370\n","Epoch 15/2000\n","80/80 [==============================] - 1s 8ms/step - loss: 149.0556 - mae: 10.1606 - val_loss: 144.3542 - val_mae: 9.9572\n","Epoch 16/2000\n","80/80 [==============================] - 1s 8ms/step - loss: 149.3147 - mae: 10.1602 - val_loss: 144.5113 - val_mae: 9.8795\n","Epoch 17/2000\n","80/80 [==============================] - 1s 8ms/step - loss: 148.8339 - mae: 10.0989 - val_loss: 144.5519 - val_mae: 9.8817\n","Epoch 18/2000\n","80/80 [==============================] - 1s 9ms/step - loss: 148.6150 - mae: 10.1427 - val_loss: 144.3322 - val_mae: 9.9333\n","Epoch 19/2000\n","80/80 [==============================] - 1s 8ms/step - loss: 149.3008 - mae: 10.1025 - val_loss: 144.3559 - val_mae: 9.9163\n","Epoch 20/2000\n","80/80 [==============================] - 1s 9ms/step - loss: 148.6933 - mae: 10.1209 - val_loss: 144.5395 - val_mae: 9.8795\n","Epoch 21/2000\n","80/80 [==============================] - 1s 8ms/step - loss: 149.1011 - mae: 10.1333 - val_loss: 144.4746 - val_mae: 9.9884\n","Epoch 22/2000\n","80/80 [==============================] - 1s 10ms/step - loss: 148.8394 - mae: 10.1672 - val_loss: 144.3813 - val_mae: 9.9130\n","Epoch 23/2000\n","80/80 [==============================] - 1s 10ms/step - loss: 148.5899 - mae: 10.1159 - val_loss: 144.3278 - val_mae: 9.9409\n","Epoch 24/2000\n","80/80 [==============================] - 1s 9ms/step - loss: 148.7167 - mae: 10.1532 - val_loss: 144.6478 - val_mae: 9.8669\n","Epoch 25/2000\n","80/80 [==============================] - 1s 9ms/step - loss: 148.4798 - mae: 10.0867 - val_loss: 144.3926 - val_mae: 9.9208\n","Epoch 26/2000\n","80/80 [==============================] - 1s 9ms/step - loss: 149.7319 - mae: 10.1416 - val_loss: 144.4263 - val_mae: 9.8915\n","Epoch 27/2000\n","80/80 [==============================] - 1s 9ms/step - loss: 149.0639 - mae: 10.1240 - val_loss: 144.3462 - val_mae: 9.9190\n","Epoch 28/2000\n","80/80 [==============================] - 1s 9ms/step - loss: 148.9420 - mae: 10.1543 - val_loss: 144.3759 - val_mae: 9.9188\n","Epoch 29/2000\n","80/80 [==============================] - 1s 8ms/step - loss: 148.9198 - mae: 10.1731 - val_loss: 144.4858 - val_mae: 9.8811\n","Epoch 30/2000\n","80/80 [==============================] - 1s 8ms/step - loss: 148.8357 - mae: 10.1221 - val_loss: 144.3909 - val_mae: 9.8968\n","Epoch 31/2000\n","80/80 [==============================] - 1s 8ms/step - loss: 149.1058 - mae: 10.1361 - val_loss: 144.8893 - val_mae: 9.8477\n","Epoch 32/2000\n","80/80 [==============================] - 1s 8ms/step - loss: 148.9992 - mae: 10.0965 - val_loss: 144.3686 - val_mae: 9.9265\n","Epoch 33/2000\n","80/80 [==============================] - 1s 8ms/step - loss: 148.9571 - mae: 10.1716 - val_loss: 145.0519 - val_mae: 9.8360\n","Epoch 34/2000\n","80/80 [==============================] - 1s 8ms/step - loss: 148.3729 - mae: 10.0705 - val_loss: 144.5423 - val_mae: 10.0038\n","Epoch 35/2000\n","80/80 [==============================] - 1s 8ms/step - loss: 149.2534 - mae: 10.1684 - val_loss: 144.3622 - val_mae: 9.9224\n","Epoch 36/2000\n","80/80 [==============================] - 1s 7ms/step - loss: 148.8502 - mae: 10.1415 - val_loss: 144.3432 - val_mae: 9.9634\n","Epoch 37/2000\n","80/80 [==============================] - 1s 8ms/step - loss: 148.9243 - mae: 10.1791 - val_loss: 144.4290 - val_mae: 9.8960\n","Epoch 38/2000\n","80/80 [==============================] - 1s 7ms/step - loss: 149.3099 - mae: 10.1229 - val_loss: 144.3765 - val_mae: 9.9676\n","Epoch 39/2000\n","80/80 [==============================] - 1s 7ms/step - loss: 148.5116 - mae: 10.1464 - val_loss: 144.7595 - val_mae: 9.8556\n","Epoch 40/2000\n","80/80 [==============================] - 1s 8ms/step - loss: 148.7529 - mae: 10.1343 - val_loss: 144.9714 - val_mae: 9.8481\n","Epoch 41/2000\n","80/80 [==============================] - 1s 7ms/step - loss: 148.9373 - mae: 10.1493 - val_loss: 144.6200 - val_mae: 9.8716\n","Epoch 42/2000\n","80/80 [==============================] - 1s 7ms/step - loss: 148.5356 - mae: 10.0803 - val_loss: 144.4387 - val_mae: 9.9871\n","Epoch 43/2000\n","80/80 [==============================] - 1s 7ms/step - loss: 148.9217 - mae: 10.1773 - val_loss: 144.8033 - val_mae: 9.8504\n","Epoch 44/2000\n","80/80 [==============================] - 1s 7ms/step - loss: 149.4260 - mae: 10.1339 - val_loss: 144.4367 - val_mae: 9.8947\n","(160, 48)\n","[[18.270273 18.029455 18.286465 ... 21.052938 20.388752 19.43363 ]\n"," [18.270247 18.029432 18.286495 ... 21.052896 20.388748 19.43365 ]\n"," [18.270235 18.029436 18.286488 ... 21.052906 20.388733 19.43366 ]\n"," ...\n"," [18.270258 18.029459 18.286465 ... 21.052927 20.38874  19.43364 ]\n"," [18.270258 18.029453 18.286486 ... 21.052927 20.388765 19.43364 ]\n"," [18.270206 18.029428 18.28647  ... 21.052896 20.388716 19.433659]]\n","[[18.270252 18.029448 18.286469 ... 21.052896 20.388739 19.433638]\n"," [18.270256 18.029448 18.286472 ... 21.052896 20.388744 19.433638]\n"," [18.270258 18.02945  18.286476 ... 21.052896 20.388746 19.43364 ]\n"," ...\n"," [18.270254 18.02945  18.286472 ... 21.052898 20.388748 19.433636]\n"," [18.27025  18.029448 18.286467 ... 21.052896 20.388742 19.433634]\n"," [18.270247 18.029448 18.286463 ... 21.052896 20.388739 19.433632]]\n","\n","Fold_4 Featuring ===========Sun Mar  5 19:12:06 2023\n","\n","Epoch 1/2000\n","80/80 [==============================] - 2s 11ms/step - loss: 288.6639 - mae: 13.1790 - val_loss: 171.7071 - val_mae: 10.1136\n","Epoch 2/2000\n","80/80 [==============================] - 1s 7ms/step - loss: 148.8703 - mae: 9.9039 - val_loss: 155.4180 - val_mae: 10.2995\n","Epoch 3/2000\n","80/80 [==============================] - 1s 8ms/step - loss: 145.5679 - mae: 10.0175 - val_loss: 155.4279 - val_mae: 10.3710\n","Epoch 4/2000\n","80/80 [==============================] - 1s 7ms/step - loss: 146.0772 - mae: 10.0432 - val_loss: 155.4720 - val_mae: 10.3858\n","Epoch 5/2000\n","80/80 [==============================] - 1s 8ms/step - loss: 145.8927 - mae: 10.0099 - val_loss: 155.4008 - val_mae: 10.3035\n","Epoch 6/2000\n","80/80 [==============================] - 1s 8ms/step - loss: 145.9194 - mae: 10.0535 - val_loss: 155.3949 - val_mae: 10.3562\n","Epoch 7/2000\n","80/80 [==============================] - 1s 8ms/step - loss: 146.0474 - mae: 10.0457 - val_loss: 155.3748 - val_mae: 10.3301\n","Epoch 8/2000\n","80/80 [==============================] - 1s 8ms/step - loss: 146.8918 - mae: 10.0545 - val_loss: 155.5227 - val_mae: 10.2689\n","Epoch 9/2000\n","80/80 [==============================] - 1s 8ms/step - loss: 146.0161 - mae: 10.0746 - val_loss: 155.8113 - val_mae: 10.2350\n","Epoch 10/2000\n","80/80 [==============================] - 1s 8ms/step - loss: 146.2000 - mae: 9.9830 - val_loss: 155.4117 - val_mae: 10.3685\n","Epoch 11/2000\n","80/80 [==============================] - 1s 8ms/step - loss: 146.3728 - mae: 10.0253 - val_loss: 155.8784 - val_mae: 10.4678\n","Epoch 12/2000\n","80/80 [==============================] - 1s 8ms/step - loss: 146.7623 - mae: 10.0894 - val_loss: 155.3874 - val_mae: 10.3447\n","Epoch 13/2000\n","80/80 [==============================] - 1s 8ms/step - loss: 145.5877 - mae: 10.0199 - val_loss: 155.4716 - val_mae: 10.3930\n","(160, 48)\n","[[18.638767 18.172241 18.56585  ... 21.576979 20.820086 19.820103]\n"," [18.638847 18.17219  18.565811 ... 21.576988 20.81999  19.820152]\n"," [18.63877  18.172207 18.5658   ... 21.576996 20.820024 19.820147]\n"," ...\n"," [18.63888  18.172215 18.565853 ... 21.576912 20.819965 19.820171]\n"," [18.638876 18.172203 18.565838 ... 21.576952 20.819979 19.820168]\n"," [18.638777 18.172216 18.565815 ... 21.577    20.820047 19.82012 ]]\n","[[18.638853 18.172209 18.565834 ... 21.576954 20.819998 19.820127]\n"," [18.638853 18.172207 18.56583  ... 21.576954 20.819998 19.820124]\n"," [18.638853 18.17221  18.565834 ... 21.576956 20.82     19.820126]\n"," ...\n"," [18.638853 18.172209 18.56583  ... 21.576954 20.82     19.820127]\n"," [18.638853 18.172209 18.56583  ... 21.576954 20.82     19.82013 ]\n"," [18.638851 18.172209 18.56583  ... 21.576952 20.82     19.82013 ]]\n","\n","Fold_5 Featuring ===========Sun Mar  5 19:12:17 2023\n","\n","Epoch 1/2000\n","80/80 [==============================] - 2s 11ms/step - loss: 288.2025 - mae: 12.9922 - val_loss: 184.6581 - val_mae: 10.8962\n","Epoch 2/2000\n","80/80 [==============================] - 1s 8ms/step - loss: 147.3665 - mae: 9.7354 - val_loss: 161.9562 - val_mae: 10.8781\n","Epoch 3/2000\n","80/80 [==============================] - 1s 8ms/step - loss: 145.1570 - mae: 9.9285 - val_loss: 161.7230 - val_mae: 10.8936\n","Epoch 4/2000\n","80/80 [==============================] - 1s 8ms/step - loss: 144.3791 - mae: 9.8525 - val_loss: 161.6295 - val_mae: 10.9060\n","Epoch 5/2000\n","80/80 [==============================] - 1s 8ms/step - loss: 145.0253 - mae: 9.8846 - val_loss: 161.5074 - val_mae: 10.9455\n","Epoch 6/2000\n","80/80 [==============================] - 1s 8ms/step - loss: 144.6024 - mae: 9.9094 - val_loss: 161.8335 - val_mae: 10.8850\n","Epoch 7/2000\n","80/80 [==============================] - 1s 8ms/step - loss: 144.4284 - mae: 9.8531 - val_loss: 162.2518 - val_mae: 10.8574\n","Epoch 8/2000\n","80/80 [==============================] - 1s 8ms/step - loss: 144.2999 - mae: 9.8710 - val_loss: 161.5437 - val_mae: 10.9228\n","Epoch 9/2000\n","80/80 [==============================] - 1s 8ms/step - loss: 145.1056 - mae: 9.8725 - val_loss: 161.5620 - val_mae: 10.9681\n","Epoch 10/2000\n","80/80 [==============================] - 1s 8ms/step - loss: 145.0871 - mae: 9.9589 - val_loss: 161.5298 - val_mae: 10.9230\n","Epoch 11/2000\n","80/80 [==============================] - 1s 8ms/step - loss: 144.3765 - mae: 9.9115 - val_loss: 163.5653 - val_mae: 10.8144\n","Epoch 12/2000\n","80/80 [==============================] - 1s 9ms/step - loss: 144.6424 - mae: 9.8561 - val_loss: 162.3694 - val_mae: 10.8518\n","Epoch 13/2000\n","80/80 [==============================] - 1s 8ms/step - loss: 144.6074 - mae: 9.7996 - val_loss: 161.5077 - val_mae: 10.9455\n","Epoch 14/2000\n","80/80 [==============================] - 1s 8ms/step - loss: 144.9531 - mae: 9.9553 - val_loss: 161.8868 - val_mae: 10.8811\n","Epoch 15/2000\n","80/80 [==============================] - 1s 8ms/step - loss: 144.8974 - mae: 9.8751 - val_loss: 161.7166 - val_mae: 10.8959\n","Epoch 16/2000\n","80/80 [==============================] - 1s 8ms/step - loss: 144.2885 - mae: 9.8943 - val_loss: 162.6094 - val_mae: 10.8447\n","Epoch 17/2000\n","80/80 [==============================] - 1s 8ms/step - loss: 144.2413 - mae: 9.8397 - val_loss: 161.5979 - val_mae: 10.9079\n","Epoch 18/2000\n","80/80 [==============================] - 1s 8ms/step - loss: 144.5087 - mae: 9.9112 - val_loss: 161.8373 - val_mae: 10.8846\n","Epoch 19/2000\n","80/80 [==============================] - 1s 9ms/step - loss: 144.3077 - mae: 9.8905 - val_loss: 162.2262 - val_mae: 10.8597\n","Epoch 20/2000\n","80/80 [==============================] - 1s 8ms/step - loss: 145.1631 - mae: 9.8981 - val_loss: 162.1976 - val_mae: 10.8606\n","Epoch 21/2000\n","80/80 [==============================] - 1s 8ms/step - loss: 144.9208 - mae: 9.8817 - val_loss: 161.9698 - val_mae: 10.8752\n","Epoch 22/2000\n","80/80 [==============================] - 1s 8ms/step - loss: 144.4224 - mae: 9.8738 - val_loss: 161.8459 - val_mae: 10.8878\n","Epoch 23/2000\n","80/80 [==============================] - 1s 8ms/step - loss: 143.9257 - mae: 9.8433 - val_loss: 161.5646 - val_mae: 10.9184\n","Epoch 24/2000\n","80/80 [==============================] - 1s 8ms/step - loss: 144.8916 - mae: 9.8769 - val_loss: 161.9071 - val_mae: 10.8782\n","Epoch 25/2000\n","80/80 [==============================] - 1s 8ms/step - loss: 145.1172 - mae: 9.8843 - val_loss: 162.6243 - val_mae: 10.8441\n","Epoch 26/2000\n","80/80 [==============================] - 1s 8ms/step - loss: 144.1579 - mae: 9.8814 - val_loss: 161.9410 - val_mae: 10.8768\n","Epoch 27/2000\n","80/80 [==============================] - 1s 9ms/step - loss: 144.4682 - mae: 9.8945 - val_loss: 162.0071 - val_mae: 10.8774\n","Epoch 28/2000\n","80/80 [==============================] - 1s 8ms/step - loss: 144.3564 - mae: 9.9007 - val_loss: 162.2116 - val_mae: 10.8583\n","Epoch 29/2000\n","80/80 [==============================] - 1s 9ms/step - loss: 144.4942 - mae: 9.9069 - val_loss: 163.0666 - val_mae: 10.8240\n","Epoch 30/2000\n","80/80 [==============================] - 1s 8ms/step - loss: 144.9235 - mae: 9.8487 - val_loss: 162.7589 - val_mae: 10.8327\n","Epoch 31/2000\n","80/80 [==============================] - 1s 8ms/step - loss: 144.3369 - mae: 9.8455 - val_loss: 161.5054 - val_mae: 10.9138\n","Epoch 32/2000\n","80/80 [==============================] - 1s 8ms/step - loss: 144.9806 - mae: 9.9088 - val_loss: 163.2829 - val_mae: 10.8152\n","Epoch 33/2000\n","80/80 [==============================] - 1s 8ms/step - loss: 144.5344 - mae: 9.8862 - val_loss: 162.5121 - val_mae: 10.8384\n","(160, 48)\n","[[17.865393 17.50401  17.94462  ... 20.520344 19.761177 19.021593]\n"," [17.865387 17.50405  17.944628 ... 20.520357 19.761269 19.021639]\n"," [17.865395 17.50405  17.944624 ... 20.520288 19.76118  19.021582]\n"," ...\n"," [17.86656  17.520166 17.949366 ... 20.538927 19.77777  19.045942]\n"," [17.866568 17.521189 17.94963  ... 20.540094 19.778856 19.047462]\n"," [17.866537 17.52017  17.94933  ... 20.538816 19.777803 19.045858]]\n","[[17.8654   17.504042 17.944616 ... 20.520308 19.761246 19.021566]\n"," [17.86535  17.50401  17.944601 ... 20.520296 19.76121  19.021553]\n"," [17.865362 17.504015 17.944605 ... 20.520298 19.761219 19.021559]\n"," ...\n"," [17.868513 17.55021  17.9581   ... 20.57356  19.808643 19.0913  ]\n"," [17.866636 17.52161  17.949759 ... 20.540546 19.779287 19.04807 ]\n"," [17.86684  17.525229 17.950802 ... 20.54474  19.782995 19.053553]]\n"]}],"source":["import time\n","from sklearn.model_selection import KFold\n","from tensorflow.keras.layers import LSTM, Dense, Dropout, Conv1D, MaxPooling1D, Flatten, Input, BatchNormalization\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.callbacks import EarlyStopping\n","from tensorflow.keras.models import Model\n","\n","\n","# 五折交叉验证\n","folds = KFold(n_splits=5, shuffle=True, random_state=2019)\n","oof = np.zeros([len(x_train), 48])\n","predictions = np.zeros([len(x_test), 48])\n","\n","input_shape=tuple([x_train.shape[i] for i in range(1,len(x_train.shape))]) # 输入数据维度（忽略条数\n","\n","for fold_, (trn_idx, val_idx) in enumerate(\n","    folds.split(range(len(x_train)), y_train)\n","    ):\n","    # KFold五折交叉\n","    print(f'\\nFold_{fold_+1} Featuring ==========={time.asctime(time.localtime(time.time()))}\\n')\n","    X_tra, X_val = x_train[trn_idx], x_train[val_idx]\n","    y_tra, y_val = y_train[trn_idx], y_train[val_idx]\n","    \n","    model = Sequential()\n","    \n","    '''LSTM'''\n","    model.add(LSTM(320, input_shape=(x_train.shape[1], 48))) # input_shape（特征数量，特征值维数）\n","    model.add(Dropout(0.2))\n","    model.add(Dense(48))\n","\n","    '''MLP'''\n","    # model.add(Dense(320, input_shape=input_shape))\n","    # model.add(BatchNormalization())\n","    # model.add(Dense(128))\n","    # model.add(Dropout(0.2))\n","    # model.add(Dense(64))\n","    # model.add(Dense(48)) # , activation='linear'\n","\n","    '''CNN'''\n","    # 输入数据\n","    # input_tensor = Input(shape=input_shape)\n","    # # 卷积层\n","    # x = Conv1D(filters=3, kernel_size=3, activation='relu')(input_tensor)\n","    # x = MaxPooling1D(pool_size=2)(x)\n","    # # 全连接层\n","    # x = Flatten()(x)\n","    # x = Dense(units=48)(x)\n","    # # 模型定义\n","    # model = Model(input_tensor, x)\n","\n","    # 编译模型\n","    model.compile(loss='mean_squared_error', optimizer='adam',metrics=['mae'])\n","\n","    # 训练模型\n","    # x_train是特征A和特征B的训练数据，y_train是标签的训练数据\n","    # x_train和y_train需要转换成三维张量\n","    model.fit(X_tra, y_tra, epochs=2000, \n","        batch_size=8, \n","        validation_data=(X_val, y_val), \n","        callbacks=[EarlyStopping(monitor='loss', patience=10)])\n","\n","    tmp = model.predict(X_val)\n","    print(tmp.shape)\n","    print(tmp)\n","    oof[val_idx] = tmp\n","\n","    tmp = model.predict(x_test)\n","    print(tmp)\n","    predictions += tmp / folds.n_splits\n","\n","    # print(predictions)\n","    del model\n"]},{"cell_type":"code","execution_count":31,"metadata":{},"outputs":[{"ename":"AttributeError","evalue":"'tuple' object has no attribute 'reshape'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[1;32mg:\\Browser\\GAIDC_preliminary_A\\特征构造+神经网络.ipynb 单元格 25\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/g%3A/Browser/GAIDC_preliminary_A/%E7%89%B9%E5%BE%81%E6%9E%84%E9%80%A0%2B%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C.ipynb#X42sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m y_train \u001b[39m=\u001b[39m y_train\u001b[39m.\u001b[39mreshape((\u001b[39m800\u001b[39m,\u001b[39m48\u001b[39m)),\u001b[39m#  oof.shape, predictions.shape\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/Browser/GAIDC_preliminary_A/%E7%89%B9%E5%BE%81%E6%9E%84%E9%80%A0%2B%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C.ipynb#X42sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m y_train\u001b[39m.\u001b[39mshape()\n","\u001b[1;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'reshape'"]}],"source":["y_train = y_train.reshape((800,48)),#  oof.shape, predictions.shape\n","y_train.shape()"]},{"cell_type":"code","execution_count":32,"metadata":{},"outputs":[{"ename":"ValueError","evalue":"Found input variables with inconsistent numbers of samples: [1, 800]","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[1;32mg:\\Browser\\GAIDC_preliminary_A\\特征构造+神经网络.ipynb 单元格 26\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/Browser/GAIDC_preliminary_A/%E7%89%B9%E5%BE%81%E6%9E%84%E9%80%A0%2B%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C.ipynb#X33sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m mean_squared_error, mean_absolute_error\n\u001b[1;32m----> <a href='vscode-notebook-cell:/g%3A/Browser/GAIDC_preliminary_A/%E7%89%B9%E5%BE%81%E6%9E%84%E9%80%A0%2B%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C.ipynb#X33sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m score \u001b[39m=\u001b[39m mean_absolute_error(y_train, oof)\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/Browser/GAIDC_preliminary_A/%E7%89%B9%E5%BE%81%E6%9E%84%E9%80%A0%2B%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C.ipynb#X33sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m score, predictions\u001b[39m.\u001b[39mshape\n","File \u001b[1;32mc:\\Users\\Jackie r9k7\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\metrics\\_regression.py:191\u001b[0m, in \u001b[0;36mmean_absolute_error\u001b[1;34m(y_true, y_pred, sample_weight, multioutput)\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmean_absolute_error\u001b[39m(\n\u001b[0;32m    136\u001b[0m     y_true, y_pred, \u001b[39m*\u001b[39m, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, multioutput\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39muniform_average\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    137\u001b[0m ):\n\u001b[0;32m    138\u001b[0m     \u001b[39m\"\"\"Mean absolute error regression loss.\u001b[39;00m\n\u001b[0;32m    139\u001b[0m \n\u001b[0;32m    140\u001b[0m \u001b[39m    Read more in the :ref:`User Guide <mean_absolute_error>`.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    189\u001b[0m \u001b[39m    0.85...\u001b[39;00m\n\u001b[0;32m    190\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 191\u001b[0m     y_type, y_true, y_pred, multioutput \u001b[39m=\u001b[39m _check_reg_targets(\n\u001b[0;32m    192\u001b[0m         y_true, y_pred, multioutput\n\u001b[0;32m    193\u001b[0m     )\n\u001b[0;32m    194\u001b[0m     check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[0;32m    195\u001b[0m     output_errors \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39maverage(np\u001b[39m.\u001b[39mabs(y_pred \u001b[39m-\u001b[39m y_true), weights\u001b[39m=\u001b[39msample_weight, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n","File \u001b[1;32mc:\\Users\\Jackie r9k7\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\metrics\\_regression.py:94\u001b[0m, in \u001b[0;36m_check_reg_targets\u001b[1;34m(y_true, y_pred, multioutput, dtype)\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_check_reg_targets\u001b[39m(y_true, y_pred, multioutput, dtype\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mnumeric\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m     61\u001b[0m     \u001b[39m\"\"\"Check that y_true and y_pred belong to the same regression task.\u001b[39;00m\n\u001b[0;32m     62\u001b[0m \n\u001b[0;32m     63\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[39m        the dtype argument passed to check_array.\u001b[39;00m\n\u001b[0;32m     93\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 94\u001b[0m     check_consistent_length(y_true, y_pred)\n\u001b[0;32m     95\u001b[0m     y_true \u001b[39m=\u001b[39m check_array(y_true, ensure_2d\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, dtype\u001b[39m=\u001b[39mdtype)\n\u001b[0;32m     96\u001b[0m     y_pred \u001b[39m=\u001b[39m check_array(y_pred, ensure_2d\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, dtype\u001b[39m=\u001b[39mdtype)\n","File \u001b[1;32mc:\\Users\\Jackie r9k7\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:332\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    330\u001b[0m uniques \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(lengths)\n\u001b[0;32m    331\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(uniques) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m--> 332\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    333\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    334\u001b[0m         \u001b[39m%\u001b[39m [\u001b[39mint\u001b[39m(l) \u001b[39mfor\u001b[39;00m l \u001b[39min\u001b[39;00m lengths]\n\u001b[0;32m    335\u001b[0m     )\n","\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [1, 800]"]}],"source":["# from sklearn.metrics import mean_squared_error, mean_absolute_error\n","# score = mean_absolute_error(y_train, oof)\n","# score, predictions.shape"]},{"cell_type":"code","execution_count":33,"metadata":{},"outputs":[],"source":["df_test_48 = df_48.iloc[test_no_list]\n","for i,j in enumerate(df_test_48[\"y\"]):\n","    df_test_48.iloc[i,-1] = predictions[i]\n","# df_test_48[[\"id\",\"y\"]]"]},{"cell_type":"code","execution_count":34,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["9600it [00:04, 2052.04it/s]\n"]}],"source":["# df_test_48[[\"id\",]].values[0].tolist()\n","# arr.flatten()\n","test_id_list = np.concatenate(df_test_48[\"id\"].values)\n","test_y_list = np.concatenate(df_test_48[\"y\"].values)\n","df_test[[\"id\",\"y\"]]\n","\n","for i,j in tqdm(zip(test_id_list, test_y_list)):\n","    df_test.loc[df_test[\"id\"]==i,\"y\"] = j"]},{"cell_type":"code","execution_count":35,"metadata":{},"outputs":[{"data":{"text/plain":["38400    18.168720\n","38401    17.866105\n","38402    18.247434\n","38403    19.049457\n","38404    19.995107\n","           ...    \n","47995    20.606771\n","47996    21.158372\n","47997    21.031034\n","47998    20.341500\n","47999    19.428096\n","Name: y, Length: 9600, dtype: float64"]},"execution_count":35,"metadata":{},"output_type":"execute_result"}],"source":["df_test[\"y\"]"]},{"cell_type":"code","execution_count":36,"metadata":{},"outputs":[],"source":["# df_test[[\"id\",\"y\"]].to_csv(f'lstm_{int(100*score)}.csv', index=False)\n","df_test[[\"id\",\"y\"]].to_csv(f'lstm.csv', index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"},"vscode":{"interpreter":{"hash":"f5946b6e853b34f473fb738bafc13c5730ec46b1be076a90eae2c15b8d0b108b"}}},"nbformat":4,"nbformat_minor":1}
